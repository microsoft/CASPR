# -----------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Setup() configuration
# -----------------------------------------------------------------------------

[metadata]
name = AI.Models.CASPR
version = attr: caspr.__VERSION
description = CASPR
long_description = file: README.rst, LICENSE
keywords = "CASPR", "Machine Learning", "Deep Learning"
license = "Microsoft"
classifiers =
    Programming Language :: Python :: 3.7,
    Intended Audience :: Developers,
    License :: OSI Approved :: MIT License,
    Natural Language :: English,
    Operating System :: OS Independent,
    Topic :: Scientific/Engineering :: Artificial Intelligence
url = https://powerbi.visualstudio.com/Business360%%20AI/_git/AI.Models.CASPR

[options]
zip_safe = False
include_package_data = True
packages = find:

install_requires =      ## base (common) requirements
    pandas>1.0
    imbalanced-learn>=0.8
    scikit-learn>=0.7
    scipy>=1.5
    matplotlib>=3.3
    torch~=1.11.0
    protobuf<4.0
    onnx~=1.10.1
    onnxruntime~=1.7.0

[options.packages.find]
include=caspr.*
exclude=tests

[options.extras_require]

horovod =       ##  install for horovod + petastorm execution (spark.large module)
    pyspark~=3.1
    torchvision
    petastorm~=0.11
    horovod[pytorch,spark]>=0.22
    b360sparkdl>=1.0                    

xai =           ##  install for explainability
    AI.Models.Explainer~=6.0
    captum>=0.2

databricks =    ##  install on Databricks
    mlflow>=1.19  
    petastorm~=0.11

aml =           ##  install on Azure ML
    azureml-core>=1.32
    mlflow>=1.19
    azureml-mlflow>=1.32

hdi =           ##  install on HDInsights
    pyspark~=2.4.5
    numpy<1.20.0
    pyarrow~=0.17.1

test =          ##  install before test runs
    pytest         
    pytest-cov
    pylint 
    pylint-junit

dev =           ##  install for PPE, latest
    AI.Models.Explainer
    captum
    imbalanced-learn
    matplotlib
    scikit-learn
    pandas
    numpy
    torch


# -----------------------------------------------------------------------------
# Pylama Configurations
# -----------------------------------------------------------------------------
# Documentation: https://pylama.readthedocs.io/en/latest/#command-line-options
[pylama]
format = pylint
skip = */.tox/*,*/.env/*
linters = isort,mccabe,pycodestyle,pydocstyle,pyflakes,pylint
ignore = D202,D203,D213,D406,D407,D413,D415,D417


# -----------------------------------------------------------------------------
# Linter-Specific Configurations
# -----------------------------------------------------------------------------
# Possible settings: https://github.com/timothycrosley/isort/wiki/isort-Settings
[pylama:isort]
line_length = 120
multi_line_output = 0
combine_star = True
use_parentheses = True
combine_as_imports = True

# Used by isort command
[isort]
line_length = 120
multi_line_output = 0
combine_star = True
use_parentheses = True
combine_as_imports = True

# Source code: https://github.com/pycqa/mccabe
[pylama:mccabe]

# Codes: https://pycodestyle.pycqa.org/en/latest/intro.html#error-codes
[pylama:pycodestyle]
max_line_length = 120

# Used by auto-formatters
[pycodestyle]
max_line_length = 120

# Codes: http://www.pydocstyle.org/en/5.0.1/error_codes.html
[pylama:pydocstyle]

# Source code: https://github.com/PyCQA/pyflakes
[pylama:pyflakes]
max_line_length = 120
statistics = True
doctests = False
builtins = _

# Codes: https://docs.pylint.org/en/1.6.0/features.html
# Default settings: https://github.com/PyCQA/pylint/blob/master/pylintrc
[pylama:pylint]
max_line_length = 120
logging_format_style = new
attr_rgx = [a-z_][a-z0-9_]{,30}$
variable_rgx = [a-z_][a-z0-9_]{,30}$
argument_rgx = [a-z_][a-z0-9_]{,30}$
class_attribute_rgx = ([A-Za-z_][A-Za-z0-9_]{,30}|(__.*__))$
# Modules whose attributes are generated at runtime and thus attributes cannot be found using static analysis:
ignored_modules =
    pyspark.sql.functions, torch, numpy


# -----------------------------------------------------------------------------
# File-Specific Configurations
# -----------------------------------------------------------------------------
[pylama:*tests/*.py]
ignore = C0114,C0115,C0116,C0302,C0321,D,R0902,R0903,R0904,W0612,W0613,C0103,R0914

[pylama:*caspr/models/lstm_autoencoder_sequence.py]
ignore = C0103

[pylama:*caspr/models/attention_mechanisms.py]
ignore = C0103

[pylama:*caspr/utils/train.py]
ignore = W0613

[pylama:*caspr/utils/spark/large/train.py]
ignore = E1102, E1121

[pylama:*caspr/utils/spark/large/score.py]
ignore = E1121

[pylama:*caspr/utils/preprocess.py]
ignore = R0913, R0914

[pylama:*caspr/utils/spark/preprocess.py]
ignore = R0913, R0914, W0640

[pylama:*caspr/utils/explain/CASPRExplainer.py]
ignore = C0103, R0902, R0913, W0221

[pylama:*caspr/utils/explain/utils.py]
ignore = R0914

[pylama:*caspr/utils/segmentation/pandas.py]
ignore = W0703, W0102, R0913, R0914, W0612

[pylama:*caspr/utils/segmentation/dec_utils.py]
ignore = E1102, R0914

[pylama:*setup.py]
ignore = A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z
# skip = 1  # Not currently enforced
